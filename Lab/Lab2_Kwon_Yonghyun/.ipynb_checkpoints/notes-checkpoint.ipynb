{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import functools\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra\"\n",
    "TEST_DATA_URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"optdigits.tra\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"optdigits.tes\", TEST_DATA_URL)\n",
    "\n",
    "train_labels = []\n",
    "train_images = []\n",
    "with open(train_file_path, \"r\") as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for line in rdr:\n",
    "        train_labels.append(int(line[64]))\n",
    "        train_images.append([int(i) for i in line[0:64]])\n",
    "\n",
    "test_labels = []\n",
    "test_images = []\n",
    "with open(test_file_path, \"r\") as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for line in rdr:\n",
    "        test_labels.append(int(line[64]))\n",
    "        test_images.append([int(i) for i in line[0:64]])\n",
    "        \n",
    "train_labels = np.array(train_labels)\n",
    "train_images = np.array(train_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.20, shuffle= True)\n",
    "\n",
    "len_val = len(train_labels) // 5\n",
    "\n",
    "#val_labels = train_labels[-len_val:]\n",
    "#val_images = train_images[-len_val:]\n",
    "#train_labels= train_labels[:-len_val]\n",
    "#train_images = train_images[:-len_val]\n",
    "\n",
    "\n",
    "encoded_train_labels = to_categorical(train_labels)\n",
    "encoded_val_labels = to_categorical(val_labels)\n",
    "encoded_test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OneHotEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7e9302d8005f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# binary encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0monehot_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OneHotEncoder' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = train_data.iloc[:, 0:64]\n",
    "#train_labels = train_data.iloc[:, 64]\n",
    "#test_images = test_data.iloc[:, 0:64]\n",
    "#test_labels = train_data.iloc[:, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer=keras.optimizers.SGD(momentum = 0.1, learning_rate=0.1),\n",
    "#              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 12 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0 32 ... 30 32 10]\n",
      " ...\n",
      " [ 0  0 12 ...  4  0  0]\n",
      " [ 0  0 16 ... 24  2  0]\n",
      " [ 0  0  8 ...  0  0  0]]\n",
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/100\n",
      "3058/3058 [==============================] - 1s 313us/sample - loss: 1.6784 - accuracy: 0.8257 - val_loss: 0.3638 - val_accuracy: 0.8797\n",
      "Epoch 2/100\n",
      "3058/3058 [==============================] - 0s 95us/sample - loss: 0.1531 - accuracy: 0.9474 - val_loss: 0.1823 - val_accuracy: 0.9399\n",
      "Epoch 3/100\n",
      "3058/3058 [==============================] - 0s 105us/sample - loss: 0.0924 - accuracy: 0.9732 - val_loss: 0.1419 - val_accuracy: 0.9582\n",
      "Epoch 4/100\n",
      "3058/3058 [==============================] - 0s 93us/sample - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.1386 - val_accuracy: 0.9542\n",
      "Epoch 5/100\n",
      "3058/3058 [==============================] - 0s 96us/sample - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.1306 - val_accuracy: 0.9621\n",
      "Epoch 6/100\n",
      "3058/3058 [==============================] - 0s 95us/sample - loss: 0.0433 - accuracy: 0.9886 - val_loss: 0.1122 - val_accuracy: 0.9660\n",
      "Epoch 7/100\n",
      "3058/3058 [==============================] - 0s 96us/sample - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.1311 - val_accuracy: 0.9569\n",
      "Epoch 8/100\n",
      "3058/3058 [==============================] - 0s 101us/sample - loss: 0.0347 - accuracy: 0.9908 - val_loss: 0.1185 - val_accuracy: 0.9608\n",
      "3.3441994999884628\n",
      "{'batch_size': 32, 'epochs': 100, 'steps': 96, 'samples': 3058, 'verbose': 0, 'do_validation': True, 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}\n",
      "8\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_305 (Dense)            multiple                  8320      \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 9,610\n",
      "Trainable params: 9,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'loss': [1.6783604518193058, 0.15310637749356332, 0.0924146615305003, 0.06694431995949846, 0.05410136004082707, 0.04325427657798508, 0.036549525554100036, 0.03470919132135209], 'accuracy': [0.8257031, 0.9473512, 0.97318506, 0.9797253, 0.98332244, 0.9885546, 0.9901897, 0.9908437], 'val_loss': [0.363802732556474, 0.1822923205257241, 0.1419470461268051, 0.13862968079404894, 0.1305832078254301, 0.11222519995340335, 0.13105341238913193, 0.11849140997221268], 'val_accuracy': [0.87973857, 0.9398693, 0.95816994, 0.95424837, 0.9620915, 0.9660131, 0.95686275, 0.9607843]}\n",
      "0.9941138\n",
      "0.9607843\n",
      "0.01\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "nHiddenlayers = 1\n",
    "nHiddenunits = 128\n",
    "batch_size = 32\n",
    "activation='relu'\n",
    "inputScale = 2\n",
    "\n",
    "print(train_images*inputScale)\n",
    "\n",
    "#train_images = train_images * inputScale\n",
    "#test_images = test_images * inputScale\n",
    "#val_images = val_images * inputScale\n",
    "\n",
    "#model = keras.Sequential([\n",
    "#    keras.layers.Dense(128, activation='relu'),\n",
    "#    keras.layers.Dense(10, activation='softmax')\n",
    "#])\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "for i in range(int(nHiddenlayers)):\n",
    "    model.add(keras.layers.Dense(nHiddenunits, activation=activation))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr = 0.01, momentum = 0.0),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss')\n",
    "]\n",
    "start = timer()\n",
    "modelFit = model.fit(train_images * inputScale, encoded_train_labels , epochs=100, callbacks=callbacks,\n",
    "         validation_data=( val_images * inputScale, encoded_val_labels), batch_size=batch_size)\n",
    "end = timer()\n",
    "\n",
    "print(end-start)\n",
    "\n",
    "print (modelFit.params)\n",
    "\n",
    "print(len(modelFit.history['loss']))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "print(modelFit.history)\n",
    "print(model.evaluate(train_images, encoded_train_labels, verbose=0)[1])\n",
    "print(model.evaluate(val_images, encoded_val_labels, verbose=0)[1])\n",
    "\n",
    "\n",
    "\n",
    "print(keras.backend.eval(model.optimizer.lr))\n",
    "print(keras.backend.eval(model.optimizer.momentum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification Accuracy = 0.9577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall classification Accuracy = %.4f\\n\" % (accuracy_score(test_labels, predictions)))\n",
    "#test_scores = model.evaluate(test_images,  test_labels, verbose=3)\n",
    "#print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       178\n",
      "           1       0.92      0.96      0.94       182\n",
      "           2       0.99      0.95      0.97       177\n",
      "           3       1.00      0.96      0.98       183\n",
      "           4       0.97      0.99      0.98       181\n",
      "           5       0.91      0.97      0.94       182\n",
      "           6       0.98      0.98      0.98       181\n",
      "           7       0.98      0.91      0.94       179\n",
      "           8       0.95      0.91      0.93       174\n",
      "           9       0.90      0.96      0.93       180\n",
      "\n",
      "    accuracy                           0.96      1797\n",
      "   macro avg       0.96      0.96      0.96      1797\n",
      "weighted avg       0.96      0.96      0.96      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.01, 0.02],\n",
       "       [0.  , 0.02, 0.95, 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.96, 0.  , 0.01, 0.  , 0.02, 0.01, 0.01],\n",
       "       [0.  , 0.01, 0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.01, 0.  , 0.  , 0.01, 0.97, 0.  , 0.  , 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.  , 0.  , 0.01, 0.  , 0.98, 0.  , 0.01, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.01, 0.04, 0.  , 0.91, 0.  , 0.04],\n",
       "       [0.  , 0.04, 0.  , 0.  , 0.  , 0.02, 0.01, 0.  , 0.91, 0.02],\n",
       "       [0.  , 0.01, 0.  , 0.  , 0.01, 0.02, 0.  , 0.01, 0.01, 0.96]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat = tf.math.confusion_matrix(labels=test_labels, predictions=predictions).numpy()\n",
    "con_mat = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "\r",
      "  32/1000 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ecca120f3d3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train the model, iterating on the data in batches of 32 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4a0bcfaedb25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "train_labels.shuffle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
